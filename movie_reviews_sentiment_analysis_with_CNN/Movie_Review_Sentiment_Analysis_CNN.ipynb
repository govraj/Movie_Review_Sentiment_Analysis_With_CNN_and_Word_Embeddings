{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_Review_Sentiment_Analysis_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS7JJloa5Ain",
        "colab_type": "text"
      },
      "source": [
        "# Movie Review Sentiment Analysis with (CNN and Word Embedding Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWnYUZ7gCgxj",
        "colab_type": "text"
      },
      "source": [
        "# Stage1. Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtGKDDyECnpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "from os import listdir\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import re\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUIWnWSCeH_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "32e99ef0-1767-4ae8-8e02-488c5e6aba51"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVqogWgWDLAI",
        "colab_type": "text"
      },
      "source": [
        "# Stage2. Data Preparation\n",
        "\n",
        "\n",
        "1.   Loading and cleaning the data to remove punctuation and numbers.\n",
        "2.   Defining a vocabulary of preferred words.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_nvtrgUGPJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('/content/sample_data/MovieReview.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79hgmPG5Guva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7ba1e43a-c27d-4b17-d228-f093c6275401"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Petter Mattei's \"Love in the Time of Money\" is...          1\n",
              "4  Probably my all-time favorite movie, a story o...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q59J-fAVDEim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_df(df):\n",
        "  corpus=[]\n",
        "  for i in range(0,len(df)):\n",
        "    review=re.sub(\"[^a-zA-Z]\",' ',df['review'][i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    # #remove remaining tokens that are not alphabetic\n",
        "    review=[word for word in review if str(word).isalpha]\n",
        "    # remove stopwords\n",
        "    review=[word for word in review if not word in set(stopwords.words('english'))]\n",
        "    #filter out short tokens\n",
        "\t  \n",
        "    review=[word for word in review if len(word)>1]\n",
        "    corpus.append(review)\n",
        "\n",
        "  flat_tokens=[item for sublist in corpus for item in sublist]\n",
        "  return flat_tokens"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXH8jIdOZvyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  tokens=clean_df(df)\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ngmYbQ0e_t2",
        "colab_type": "text"
      },
      "source": [
        "## Define a Vocabulary\n",
        "\n",
        "* It is important to define a vocabulary of known words when using a bag-of-words or embedding model.\n",
        "\n",
        "* The more words, the larger the representation of documents, therefore it is important to constrain the words to only those believed to be predictive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_eYvbXzaPTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_token_to_vocab(df,vocab):\n",
        "  # call the clean_df function to get clean tokens\n",
        "  tokens=clean_df(df)\n",
        "  # update counts of vocab with tokens\n",
        "  vocab.update(tokens)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X4CPWRYgbUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3e2dbfc3-8171-4b90-ab34-fda2d3370e7c"
      },
      "source": [
        "# Define vocab\n",
        "vocab= Counter()\n",
        "# Add all docs to vocab\n",
        "add_token_to_vocab(df,vocab)\n",
        "# print the len of vocab\n",
        "print(len(vocab))\n",
        "# print the top 50 words of vocab\n",
        "print(vocab.most_common(50))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17510\n",
            "[('br', 4130), ('movie', 1790), ('film', 1558), ('one', 1009), ('like', 804), ('good', 540), ('even', 528), ('see', 525), ('would', 497), ('story', 462), ('time', 457), ('really', 456), ('get', 414), ('well', 412), ('much', 400), ('people', 364), ('bad', 353), ('made', 353), ('first', 352), ('way', 347), ('also', 347), ('great', 345), ('movies', 339), ('think', 314), ('make', 307), ('plot', 292), ('watch', 288), ('many', 285), ('characters', 278), ('never', 275), ('two', 273), ('little', 271), ('life', 271), ('could', 271), ('character', 270), ('films', 265), ('best', 264), ('seen', 256), ('know', 250), ('acting', 249), ('man', 241), ('ever', 231), ('show', 230), ('go', 229), ('scene', 229), ('scenes', 227), ('love', 220), ('better', 219), ('back', 217), ('still', 208)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhjRHLxJiDlR",
        "colab_type": "text"
      },
      "source": [
        "We can step through the vocabulary and remove all words that have a low occurrence, such as only being used once or twice in all reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd-hDUd-iFM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c381fc52-60a6-40e1-fec1-e42f5c93536f"
      },
      "source": [
        "# keep tokens with a min occurrence\n",
        "min_occurane = 2\n",
        "tokens = [k for k,c in vocab.items() if c >= min_occurane]\n",
        "tokens = [each for each in tokens if each!='br']\n",
        "print(len(tokens))\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XF8T5ULjUxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save vocab list to file\n",
        "def save_list(lines,filename):\n",
        "  # convert lines to a single blob of text\n",
        "\tdata = '\\n'.join(lines)\n",
        "\t# open file\n",
        "\tfile = open(filename, 'w')\n",
        "\t# write text\n",
        "\tfile.write(data)\n",
        "\t# close file\n",
        "\tfile.close()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJPZ52VJkl_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save tokens to a vocabulary file\n",
        "save_list(tokens, 'vocab.txt')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfqSyfDFk8qq",
        "colab_type": "text"
      },
      "source": [
        "Now we have vocab.txt with only the words we are interested in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JOvkY1CouG3",
        "colab_type": "text"
      },
      "source": [
        "# 3. Train Embedding Layer\n",
        "\n",
        "* In this section, we will learn a word embedding while training a neural network on the classification problem.\n",
        "\n",
        "* A word embedding is a way of representing text where each word in the vocabulary is represented by a real valued vector in a high-dimensional space. The vectors are learned in such a way that words that have similar meanings will have similar representation in the vector space (close in the vector space). \n",
        "\n",
        "* The real valued vector representation for words can be learned while training the neural network. We can do this in the Keras deep learning library using the Embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKaopGz6kzRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load vocab doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        " \n",
        "# load the vocabulary\n",
        "vocab_filename = 'vocab.txt'\n",
        "vocab = load_doc(vocab_filename)\n",
        "vocab = vocab.split()\n",
        "vocab = set(vocab)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW9Fi683p9lX",
        "colab_type": "text"
      },
      "source": [
        "### we need to load all of the training data movie reviews. updated_clean_doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuXhu8pAqOtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def updated_clean_doc(df,vocab):\n",
        "  corpus=[]\n",
        "\n",
        "  for i in range(0,len(df)):\n",
        "    review = df['review'][i]\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    # filter out tokens not in vocab\n",
        "    review = [w for w in review  if w in vocab]\n",
        "\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EffemOrkr-ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load training reviews\n",
        "train_review=updated_clean_doc(df,vocab)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xQqfpG3vSwe",
        "colab_type": "text"
      },
      "source": [
        "* The next step is to encode each document as a `sequence of integers`.\n",
        "\n",
        "* The `Keras Embedding` layer requires integer inputs where each integer maps to a single token that has a specific real-valued vector representation within the embedding. These vectors are random at the beginning of training, but during training become meaningful to the network.\n",
        "\n",
        "* We can encode the training documents as sequences of integers using the `Tokenizer` class in the Keras API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5pv4B8GvAYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "tokenizer.fit_on_texts(train_review)\n",
        "\n",
        "# encode the reviews in the training dataset. We can do that by calling the texts_to_sequences()\n",
        "# function on the Tokenizer.\n",
        "\n",
        "# sequence encode\n",
        "encoded_docs = tokenizer.texts_to_sequences(train_review)\n",
        "\t\n",
        "# pad sequences\n",
        "max_length = max([len(s.split()) for s in train_review])\n",
        "Xtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n850D1EXxIVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the training labels\n",
        "ytrain=array(df['sentiment'])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3BVumVZ0n29",
        "colab_type": "text"
      },
      "source": [
        "## Load test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTZuELiuxoeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8dc9cd8b-a32b-4aae-fe8d-b879548e2064"
      },
      "source": [
        "df_test=pd.read_csv('/content/sample_data/movie_review_test.csv')\n",
        "df_test.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nothing is sacred. Just ask Ernie Fosselius. T...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This film really used its locations well with ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Strangely enough this movie never made it to t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In Nordestina, a village in the middle of nowh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"I like cheap perfume better; it doesn't last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  Nothing is sacred. Just ask Ernie Fosselius. T...          1\n",
              "1  This film really used its locations well with ...          1\n",
              "2  Strangely enough this movie never made it to t...          1\n",
              "3  In Nordestina, a village in the middle of nowh...          1\n",
              "4  \"I like cheap perfume better; it doesn't last ...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Fd0SaN07Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing with test data\n",
        "test_review=updated_clean_doc(df_test,vocab)\n",
        "# sequence encode\n",
        "encoded_docs = tokenizer.texts_to_sequences(test_review)\n",
        "# pad sequences\n",
        "Xtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "# define the test labels\n",
        "ytest=array(df_test['sentiment'])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kSGImW-1sp0",
        "colab_type": "text"
      },
      "source": [
        "## We are now ready to define our neural network model.\n",
        "\n",
        "* The model will use an Embedding layer as the first hidden layer. \n",
        "* The Embedding requires the specification of the vocabulary size, the size of the real-valued vector space, and the maximum length of input documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1cwihv01mtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define vocabulary size (largest integer value)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIaqOkXH2fVL",
        "colab_type": "text"
      },
      "source": [
        "The complete model definition is listed below including the Embedding layer.\n",
        "\n",
        "* We use a Convolutional Neural Network (CNN) as they have proven to be successful at document classification problems.\n",
        "\n",
        "* the 2D output from the CNN part of the model is flattened to one long 2D vector to represent the ‘features’ extracted by the CNN. \n",
        "* The back-end of the model is a standard Multilayer Perceptron layers to interpret the CNN features.\n",
        "* The output layer uses a sigmoid activation function to output a value between 0 and 1 for the negative and positive sentiment in the review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkPgH2Re2jEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "a1e5a1a9-06db-4ec1-e520-beab99d74c9e"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 486, 100)          883500    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 479, 32)           25632     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 239, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 7648)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                76490     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 985,633\n",
            "Trainable params: 985,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTGXhTDQ3B0Q",
        "colab_type": "text"
      },
      "source": [
        "## Next, we fit the network on the training data.\n",
        "\n",
        "* We use a binary cross entropy loss function because the problem we are learning is a binary classification problem. \n",
        "* The efficient Adam implementation of stochastic gradient descent is used and we keep track of accuracy in addition to loss during training. \n",
        "* The model is trained for 10 epochs, or 10 passes through the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwjEGtcJ2ssR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "5d47c471-34b9-486e-e4a9-f22ac3f1a1cb"
      },
      "source": [
        "# compile network\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model.fit(Xtrain, ytrain, epochs=10, verbose=2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 - 3s - loss: 0.6959 - accuracy: 0.4880\n",
            "Epoch 2/10\n",
            "32/32 - 3s - loss: 0.6377 - accuracy: 0.6920\n",
            "Epoch 3/10\n",
            "32/32 - 3s - loss: 0.3684 - accuracy: 0.9500\n",
            "Epoch 4/10\n",
            "32/32 - 3s - loss: 0.0666 - accuracy: 0.9940\n",
            "Epoch 5/10\n",
            "32/32 - 3s - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "32/32 - 3s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "32/32 - 3s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "32/32 - 3s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "32/32 - 3s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "32/32 - 3s - loss: 8.3461e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1632e9cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsewV99y357Q",
        "colab_type": "text"
      },
      "source": [
        "After the model is fit, it is evaluated on the test dataset. This dataset contains words that we have not seen before and reviews not seen during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-fkCM5g3qrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3aaa02e9-d68b-4a8e-f263-2b7c43edabac"
      },
      "source": [
        "# evaluate\n",
        "loss, acc = model.evaluate(Xtest, ytest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 76.400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnE01-5W4C9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}